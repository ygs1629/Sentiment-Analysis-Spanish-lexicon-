---
title: "Minería de opinión con léxico en castellano"
author: "Juan Luis German Saura"
date: "Sept-2025"
output:
  prettydoc::html_pretty:
    toc: True
    theme: cayman
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE, message = FALSE)
```

\

## Introducción

\
\
Los datos no estructurados representan una dimensión altamente valiosa en el panorama actual de la ciencia de datos. Al carecer de una estructura u organización predefinida, requieren ser etiquetados dentro de un marco conceptual específico para extraer información significativa de esta aparente desorganización. Independientemente de la metodología elegida, siempre existen limitaciones de las que es crucial ser consciente (interpretación subjetiva del lenguaje), aunque esto no disminuye el enorme potencial que surge al poder capturar y analizar la representación de la realidad a través del lenguaje natural.\
\
Por ello, nace la necesidad de abordar este desafío, inspirándose en una tarea académica del grado universitario cursado (BIA). Su objetivo principal es aplicar técnicas de minería de opinión en español para analizar reseñas de películas, explorando la relación entre la polaridad de los comentarios y factores como el género cinematográfico y la puntuación promedio.\
\
Este proyecto analiza reseñas de películas (datos ocultos por razones de privacidad) para evaluar su polaridad de sentimiento mediante un enfoque léxico y modelos supervisados. Se emplean técnicas de procesamiento de texto (tokenización, limpieza, matriz término-documento) y modelos de clasificación como Naïve Bayes y Regresión Logística. La evaluación se realiza mediante métricas estándar de clasificación: accuracy, precisión, recall y F1. Se utilizan herramientas de R, tidyverse, tm, wordcloud y ggplot2, desarrollando habilidades en análisis de texto, preprocesamiento, modelado supervisado y visualización de datos.\
\
\

## Preparación de datos para modelo léxico

\
En primer lugar, se hace la carga de las librerías y el conjunto de datos. Seguidamente, se carga el código que contiene el filtrado de léxico, para poder disponer de un diccionario que permita calcular la polaridad del texto en la lengua española. Para evitar interpretaciones erradas, se hace una serie de transformaciones que aseguran que las variables derivadas sean comparables y que el ruido del lenguaje natural no afecte los resultados de clasificación.\
\

```{r}
library(tidyverse)
library(tidytext)
library(rio)
library(ggplot2)
library(dplyr)
library(syuzhet)
library(tidyverse)
library(tm)
library(wordcloud)
library(caret)
library(e1071)  
library(glmnet) 
library(kableExtra)
library(DT)
```

```{r,echo=FALSE}
datos <- import("https://www.uv.es/montoro/dne/data/reviews_filmaffinity.Rdata")
```

```{r,echo=TRUE, results='hide'}
nrc_sp <- get_sentiment_dictionary(dictionary = "nrc",language = "spanish") %>% 
  filter(sentiment %in% c("positive","negative")) %>% distinct()
nrc_sp$word <- tolower(nrc_sp$word)


nrc_sp %>% group_by(word) %>% summarise(n=n()) %>% arrange(desc(n)) %>% 
  tibble() %>% filter(n>1)
nrc_sp %>% filter(word=="encantado") 
lista_duplicados <- nrc_sp %>% count(word,sort = TRUE) %>% filter(n>1) %>% pull(word)
lista_duplicados
nrc_sp <- nrc_sp %>% filter(!word %in% lista_duplicados)
```

\
Cabe resaltar que, en el análisis léxico directo, el conteo palabra a palabra permite una mayor interpretabilidad y fidelidad en la medición de polaridad, por lo que la eliminación de términos poco frecuentes podría ocasionar una pérdida de información significativa, siendo menos recomendable en este contexto.\
\
De esta forma, ya se encuentran los detalles preparados para poder analizar la polaridad en las reseñas del público sobre películas producidas en el cine español.\
\

## Análisis polaridad

\
\
Para poder desarrollar el análisis de polaridad sobre las reseñas individuales y luego sobre las películas, esta acción compleja se divide en unas partes claramente delimitadas.\
\
En primer lugar, se descompone el corpus de documentos en cada uno de los tokens que lo compone, para posteriormente poder hacer una comparación mediante el diccionario de sentimientos NCR para clasificar al token correspondiente según si su naturaleza es positiva o negativa.\
\

```{r}
tokens <- datos %>%
  unnest_tokens(word, review_text) %>%
  inner_join(nrc_sp, by = "word")
```

\
En segundo lugar, se elaboran los cálculos pertinentes para el análisis individual por reseña y el total por película. Para ello, se hace una agrupación según el título de la película y el título de la reseña y seguido de ello, se calcula el total de palabras positivas, negativas, el número de tokens totales y la polaridad de (diferencia entre las positivas y negativas).\

```{r}
polaridad_resenas <- tokens %>%
  group_by(film_name, review_title) %>%
  summarise(
    positive = sum(sentiment == "positive", na.rm = TRUE),  
    negative = sum(sentiment == "negative", na.rm = TRUE),  
    sentiment = positive - negative,                       
    total_token = n(),                                 
    .groups = 'drop')

head(polaridad_resenas)
```

\
Se puede ver que se ha conseguido con éxito lo que se pretendía generar, ya que se ha permitido evaluar la polaridad individual de cada resena antes de agrupar los resultados para cada película.\
\
Por último, se agregan las reseñas por película y se intenta conseguir la polaridad total por película, la polaridad media por reseña y por token, así como el total de reseñas y token por película.\

```{r}
agregado_pelicula <- polaridad_resenas %>%
  group_by(film_name) %>%
  summarise(
    polaridad_total_pelicula = sum(sentiment, na.rm = TRUE),  
    polaridad_media_resena = mean(sentiment, na.rm = TRUE),   
    total_resenas = n(),                                      
    total_tokens_pelicula = sum(total_token, na.rm = TRUE),  
    polaridad_media_token = polaridad_total_pelicula / total_tokens_pelicula,  
    .groups = 'drop')

head(agregado_pelicula)
```

\
Con estos valores, se ha permitido la evaluación sobre cómo varía el tono general ya sea positivo o negativo para cada película en su conjunto, facilitando la comparación entre largometrajes.\
\

## Conjunto de datos con medidas de polaridad y metavariables

\
Para poder llegar a hacer una examinación más rica y profunda, se opta por fusionar las metavariables iniciales que se contenían en el dataframe incial junto con las medidas de polaridad recientemente generadas.\

```{r}
df_final <- agregado_pelicula %>%
  left_join(select(datos, film_name, gender, film_avg_rate), by = "film_name")%>% 
  distinct()

head(df_final)
```

\
Con una inspección inicial saltan a la vista ciertos patrones. Algunos de estos son la posible relación entre la polaridad media por reseña y el género sobre el que se hace la reseña, ya que por ejemplo parece que las películas que son del tipo de comedia son las que más valoraciones positivas reciben ("Ahora o nunca" y "Campeones").\
\
Asimismo, se tendría que indagar más sobre la polaridad total que tiene cada película y la valoración que otorga el público, ya que "Ahora o nunca", tiene una polaridad alta y una valoración suspensa. Esto puede ser un indicio sobre una posible discrepancia entre la percepción del público y las reseñas críticas.\
\

## EDA

\
En esta sección se realiza un análisis exploratorio de los datos con el objetivo de identificar patrones y relaciones antes de entrenar modelos supervisados. Se combinan métricas descriptivas, análisis de correlación y visualizaciones léxicas para comprender cómo varía la polaridad de las reseñas según la puntuación promedio y el género cinematográfico.\
\
Como punto de partida, se calculan métricas básicas que ofrecen un contexto general: número total de reseñas y películas, ratio de reseñas positivas frente a negativas y las películas con polaridad extrema. Esta primera aproximación muestra una clara mayoría de reseñas positivas, aunque con una dispersión considerable entre títulos, lo que sugiere que la distribución del sentimiento podría no ser uniforme.\
\

```{r}
metricas_descriptivas <- list(
  total_resenas = nrow(polaridad_resenas),
  total_peliculas = nrow(agregado_pelicula),
  ratio_positivo_negativo = round(sum(polaridad_resenas$sentiment > 0) / sum(polaridad_resenas$sentiment < 0), 2),
  pelicula_mas_positiva = paste0(agregado_pelicula$film_name[which.max(agregado_pelicula$polaridad_total_pelicula)],
                                 " (", max(agregado_pelicula$polaridad_total_pelicula), ")"),
  pelicula_mas_negativa = paste0(agregado_pelicula$film_name[which.min(agregado_pelicula$polaridad_total_pelicula)],
                                 " (", min(agregado_pelicula$polaridad_total_pelicula), ")"))

metricas_df <- data.frame(
  Metrica = c("Total de reseñas analizadas", 
              "Total de películas",
              "Ratio positivo/negativo",
              "Película con mayor polaridad positiva",
              "Película con mayor polaridad negativa"),
  Valor = unlist(metricas_descriptivas))

metricas_clean <- data.frame(Valor = metricas_df$Valor)
rownames(metricas_clean) <- metricas_df$Metrica

metricas_clean %>%
  kbl(caption = "<div style='text-align: center; font-weight: bold; font-size: 18px; margin-bottom: 10px;'>Métricas descriptivas del análisis</div>",
      escape = FALSE) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE,
                position = "center") %>%
  column_spec(1, bold = TRUE, width = "150px") %>%
  row_spec(4, bold = TRUE, color = "black", background = "#d4edda") %>%  # Verde claro
  row_spec(5, bold = TRUE, color = "black", background = "#f8d7da") %>%  # Rojo claro
  kable_classic(full_width = FALSE, html_font = "Arial")
```

\
Esta primera aproximación muestra una clara mayoría de reseñas positivas, aunque con una dispersión considerable entre títulos, lo que sugiere que la distribución del sentimiento podría no ser uniforme.\
\
A continuación, se evalúa de manera rigurosa la relación entre la puntuación media de las películas y la polaridad media de las reseñas mediante el cálculo de correlaciones globales y segmentadas por género.\

```{r}
df_final <- df_final %>% mutate(film_avg_rate = as.numeric(gsub(",", ".", film_avg_rate)))

cor_global <- cor(df_final$film_avg_rate, 
                  df_final$polaridad_media_resena, use = "complete.obs")

cor_segmented <- df_final %>%
  group_by(gender) %>%
  summarise(correlation = cor(film_avg_rate, polaridad_media_resena,
                              use = "complete.obs")) %>%
  mutate(cor_label = paste(gender, ": r =", round(correlation, 2)))
```

\
Los resultados evidencian una correlación global muy débil (-0.1), reforzada por diferencias notables entre géneros: mientras aventuras y romance presentan relaciones positivas, drama y thriller tienden a lo contrario. Esto indica que no existe una relación lineal clara entre ambas variables, y que probablemente influyan factores adicionales.\

```{r}
ggplot(df_final, aes(x = film_avg_rate, y = polaridad_media_resena, color = gender)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, aes(group = gender)) +
  labs(title = paste("Correlación global:", round(cor_global, 2)),
       x = "Puntuación media de la película",
       y = "Polaridad media de las resenas") +
  theme_minimal() +
  scale_color_discrete(name = "Género")
```

\
Otra perspectiva a analizar es la distribución de la polaridad según el género, que aportarán más contexto al resultado encontrado en la correlación.\

```{r}
ggplot(polaridad_resenas, aes(x = sentiment, fill = ..x.. > 0)) +
  geom_histogram(bins = 30, alpha = 0.7) +
  facet_wrap(~ datos$gender[match(polaridad_resenas$film_name, datos$film_name)], 
             scales = "free_y") +
  labs(title = "Distribución de polaridad por género cinematográfico",
       x = "Polaridad de reseña", 
       y = "Frecuencia") +
  scale_fill_manual(values = c("red", "green"), 
                    name = "Sentimiento",
                    labels = c("Negativo", "Positivo")) +
  theme_minimal()
```

\
Aunque la mayoría de reseñas son positivas, cada género canaliza emociones de forma distinta. Por ejemplo, en el terror abundan expresiones negativas que reflejan la naturaleza del género más que una valoración negativa de la calidad. Así, el género condiciona el tono de las reseñas pero no necesariamente su puntuación.\
\
Para indagar más en el análisis, se opta por graficar la frecuencia de la distribución de clases de sentimiento dentro del dataframe.\

```{r}
distribucion_clases <- data.frame(
  Clase = c("Muy Negativo", "Negativo", "Neutral", "Positivo", "Muy Positivo"),
  Count = c(
    sum(polaridad_resenas$sentiment < -5),
    sum(polaridad_resenas$sentiment >= -5 & polaridad_resenas$sentiment < 0),
    sum(polaridad_resenas$sentiment == 0),
    sum(polaridad_resenas$sentiment > 0 & polaridad_resenas$sentiment <= 5),
    sum(polaridad_resenas$sentiment > 5)
  )
)

ggplot(distribucion_clases, aes(x = Clase, y = Count, fill = Clase)) +
  geom_bar(stat = "identity") +
  labs(title = "Distribución de clasificaciones de sentimiento",
       x = "Categoría de sentimiento",
       y = "Número de reseñas") +
  theme_minimal() +
  scale_fill_brewer(palette = "RdYlGn")
```

\
Con este gráfico se observa que la mayoría de reseñas tienden a ser positivas, aunque también existe una proporción relevante de valoraciones negativas y neutras. Sin embargo, este predominio de positividad no se traduce en una relación consistente con la puntuación media de las películas, tal como demuestran la correlación débil y las diferencias según género.\
\
Tomando en consideración lo anterior, no se puede descartar la hipótesis de que el comportamiento mayoritario de las reseñas refleja tendencias emocionales de los usuarios, pero no constituye un predictor fiable de la valoración numérica de las películas.\
\
Finalmente, para complementar los resultados numéricos, se representan las nubes de palabras más frecuentes en reseñas positivas y negativas.\
\

```{r}
palabras_por_clase <- tokens %>%
  mutate(clase_sentimiento = ifelse(sentiment == "positive", 
                                    "Positivo", "Negativo")) %>%
  group_by(clase_sentimiento, word) %>%
  summarise(frecuencia = n(), .groups = "drop") %>%
  group_by(clase_sentimiento) %>%
  slice_max(frecuencia, n = 20)

palabras_positivas <- filter(palabras_por_clase, clase_sentimiento == "Positivo")

wordcloud(words = palabras_positivas$word, 
          freq = palabras_positivas$frecuencia,
          max.words = 50,
          scale = c(3, 0.5),    
          min.freq = 1,         
          random.order = FALSE, 
          rot.per = 0.2,       
          colors = brewer.pal(9, "Greens"),
          fixed.asp = TRUE)
```

\

```{r}
palabras_negativas <- filter(palabras_por_clase, clase_sentimiento == "Negativo")

wordcloud(words = palabras_negativas$word, 
          freq = palabras_negativas$frecuencia,
          max.words = 50,
          scale = c(3,1.5),    
          min.freq = 1,         
          random.order = FALSE, 
          rot.per = 0.2,       
          colors = brewer.pal(9,"Reds"),
          fixed.asp = TRUE)
```

\
Las reseñas positivas destacan aspectos técnicos y cualidades abstractas valoradas por los espectadores, mientras que las negativas se centran en debilidades narrativas y expectativas incumplidas. Estas visualizaciones cualitativas refuerzan la interpretación conseguida de que el contenido del discurso de los usuarios ofrece matices que no se reflejan en las métricas numéricas, confirmando la heterogeneidad del análisis.\
\

## Preparación y preprocesamiento de datos para modelos supervisados

\
Los modelos supervisados pueden ser una alternativa para la tarea que hasta ahora solo estaba haciendo el método léxico. Ello se debe a que estos no dependen de la valoración de puntuación que tiene asignada el diccionario usado para el método anterior, ya que estos se dedican a capturar combinaciones de palabras inadvertidas anteriormente.Adicionalmente, se ajustan mejor al contexto específico sobre el que se utilizan. Debido a esto, merecen una comparativa frente al modelo léxico por las ventajas que ofrecen por su mayor (aparente) precisión, sin olvidar que este tipo de modelos suelen ser más costoso computacionalmene en su fase de entranamiento.\
\
Para poder implementar estos modelos, se pasa a la transformación la variable de puntuación en formato numérico y se genera la variable objetivo binaria. A continuación, se realiza el habitual preprocesamiento con la correspondiente tokenización, limpieza, eliminación de palabras vacías y creación de la matriz término-documento.\
\
Opuesto al método inicial, en los modelos supervisados, la reducción de dimensionalidad resulta útil para filtrar términos escasos que generan ruido en la matriz término-documento, mejorando la eficiencia y la capacidad de generalización de los algoritmos.\
\
Estas transformaciones aseguran que los datos sean adecuados para el entrenamiento de modelos supervisados.\
\

```{r}
datos_supervisado <- datos %>%
  mutate(rating_num = as.numeric(gsub(",", ".", film_avg_rate)),
         clase = ifelse(rating_num >= 6, "positivo", "negativo")) %>%
  filter(!is.na(clase)) %>%
  select(review_text, clase, film_name, film_avg_rate) %>%
  distinct()

crear_matriz_documentos <- function(textos) {
  corpus <- Corpus(VectorSource(textos))
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeNumbers)
  corpus <- tm_map(corpus, removeWords, stopwords("spanish"))
  corpus <- tm_map(corpus, stripWhitespace)
  
  dtm <- DocumentTermMatrix(corpus)
  return(dtm)
}

dtm <- crear_matriz_documentos(datos_supervisado$review_text)

dtm_reducido <- removeSparseTerms(dtm, 0.995)
matriz_datos <- as.matrix(dtm_reducido)
```

\
\

## Entrenamiento de modelos supervisados

\
Se entrenan modelos de Naïve Bayes y Regresión Logística para clasificar las reseñas, utilizando una partición estratificada de los datos entre train set y test set. Este procedimiento asegura que la evaluación del modelo refleje fielmente su capacidad de generalización. La comparación entre enfoques permite identificar qué método captura de manera más consistente la relación entre el léxico empleado y la polaridad de las reseñas, aportando información sobre la robustez de las técnicas aplicadas.\

```{r}
set.seed(123)
indices_entrenamiento <- createDataPartition(datos_supervisado$clase, p = 0.8, list = FALSE)

datos_entrenamiento <- matriz_datos[indices_entrenamiento, ]
datos_prueba <- matriz_datos[-indices_entrenamiento, ]
clase_entrenamiento <- datos_supervisado$clase[indices_entrenamiento]
clase_prueba <- datos_supervisado$clase[-indices_entrenamiento]


modelo_nb <- naiveBayes(datos_entrenamiento, clase_entrenamiento)

modelo_lr <- cv.glmnet(datos_entrenamiento, 
                       as.numeric(clase_entrenamiento == "positivo"),
                       family = "binomial", alpha = 1)
```

\
\

## Evaluación y comparativa entre modelos

\
La evaluación se centra en métricas de clasificación estándar(accuracy, recall, F1 y Kappa) que proporcionan una visión integral del rendimiento de cada modelo. Esta evaluación complementa el análisis previo de correlación, mostrando cómo las relaciones léxicas detectadas se traducen en capacidad predictiva.\

```{r}
predicciones_nb <- predict(modelo_nb, datos_prueba)
predicciones_lr <- predict(modelo_lr, datos_prueba, type = "response")
predicciones_lr <- ifelse(predicciones_lr > 0.5, "positivo", "negativo")


calcular_polaridad_texto <- function(texto) {
  tokens <- data.frame(word = unlist(strsplit(tolower(texto), "\\s+")))
  sentimiento <- tokens %>%
    inner_join(nrc_sp, by = "word") %>%
    summarise(total = sum(ifelse(sentiment == "positive", 1, -1), na.rm = TRUE))
  return(ifelse(sentimiento$total > 0, "positivo", "negativo"))
}

predicciones_lexico_prueba <- sapply(datos_supervisado$review_text[-indices_entrenamiento], 
                                     calcular_polaridad_texto)
```

\
\
Tanto mediante la tabla como con el gráfico combinado, se puede comprobar que, a rasgos generales, el mejor clasificador es el de regresión logística. Solamente bajo algún contexto específico se podría argumentar el uso de otro método por encima de este.\
\
La regresión logística demuestra un rendimiento excepcional, con una accuracy del 91.6% y un Kappa de 0.807, lo que indica una mejora significativa en sus predicciones respecto a hacerlas aleatoriamente, por lo que demuestra una capacidad sobresaliente para capturar patrones subyacentes. Su equilibrio entre precisión y exhaustividad (F1 = 0.868) confirma su robustez para esta tarea.\
\
El Naïve Bayes presenta un rendimiento moderadamente aceptable (accuracy = 77.3%, Kappa = 0.555), mostrando una mejora sobre el azar pero lejod del enfoque de regresión logística. Es importante destacar que su valor F1 (0.742) es muy cercano a su accuracy global (0.773), lo que sugiere que alguna de sus métricas específicas por clase (ya sea recall o precisión) debe ser particularmente alta. Esto indica que si el contexto de aplicación valora especialmente la identificación de una clase específica el Naïve Bayes podría ser una alternativa viable, teniendo consciencia del trade-off entre mejor identificación de la clase de interés en detrimento de la precisión global.\
\
El enfoque léxico, por el contrario, evidencia serias limitaciones. Con una accuracy del 52.5% y un Kappa negativo (-0.025), este método no solo falla en mejorar sobre el azar, sino que realiza predicciones sistemáticamente peores que una elección aleatoria. Su valor F1 de 0.347 confirma su incapacidad para realizar clasificaciones útiles en este contexto. Estos resultados subrayan deficiencias claves en la interpretación del contexto y el dominio del área pueden ser elementos claves en el desempeño del modelo.\
Por ello, en la gran mayoría de aplicaciones prácticas la elección preferida sería la regresión logística. Únicamente en escenarios concretos, Naïve Bayes podría ser una opción atractiva.\
\

```{r}
calcular_metricas <- function(reales, predicciones) {
  confusion_matrix <- confusionMatrix(factor(predicciones), factor(reales))
  accuracy <- confusion_matrix$overall["Accuracy"]
  f1 <- confusion_matrix$byClass["F1"]
  kappa <- confusion_matrix$overall["Kappa"]  
  
  return(data.frame(Accuracy = accuracy, 
                    F1 = f1,
                    Kappa = kappa))  
}

comparativa_final <- data.frame (clase = clase_prueba,
                    prediccion_lexico = predicciones_lexico_prueba)

metricas_nb <- calcular_metricas(clase_prueba, predicciones_nb)
metricas_lr <- calcular_metricas(clase_prueba, predicciones_lr)
metricas_lexico <- calcular_metricas(comparativa_final$clase, comparativa_final$prediccion_lexico)


comparativa_completa <- rbind(
  data.frame(Enfoque = "Léxico", metricas_lexico),
  data.frame(Enfoque = "Naïve Bayes", metricas_nb),
  data.frame(Enfoque = "Regresión Logística", metricas_lr))

rownames(comparativa_completa) <- comparativa_completa$Enfoque
comparativa_completa$Enfoque <- NULL

comparativa_completa %>%
  kbl(caption = "",
      digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover")) %>%
  row_spec(which.max(comparativa_completa$Kappa), 
           background = "#e6f7ff", bold = TRUE)
```

\

```{r}
comparativa_grafico <- comparativa_completa %>%
  tibble::rownames_to_column(var = "Enfoque") %>%
  pivot_longer(cols = -Enfoque, 
               names_to = "Metrica", 
               values_to = "Valor")
ggplot(comparativa_grafico, aes(x = Metrica, y = Valor, fill = Enfoque)) +
  geom_col(position = position_dodge(width = 0.8), width = 0.7, alpha = 0.8) +
  geom_text(aes(label = round(Valor, 3)), 
            position = position_dodge(width = 0.8), 
            vjust = ifelse(comparativa_grafico$Valor < 0, 1.5, -0.5),  
            size = 3.5,
            fontface = "bold") +
  labs(title = "Comparación de métricas por enfoque de clasificación",
       x = "Métrica",
       y = "Valor",
       fill = "Enfoque") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
    axis.title = element_text(face = "bold"),
    axis.text.x = element_text(face = "bold", size = 10),
    legend.position = "bottom",
    legend.title = element_text(face = "bold")
  ) +
  scale_fill_manual(values = c("#1f77b4", "#ff7f0e", "#2ca02c")) +
  scale_y_continuous(limits = c(-0.25, 1),  # Límite inferior extendido a -0.25
                     breaks = seq(-0.25, 1, 0.25),  # Marcas cada 0.25 desde -0.25
                     labels = function(x) ifelse(x < 0, 
                                                 paste0(format(x, nsmall = 2)), 
                                                 scales::percent_format(accuracy = 1)(x))) +
  scale_x_discrete(labels = c("Accuracy", "F1", "Kappa")) +
  geom_hline(yintercept = 0, color = "black", linewidth = 0.5)
```

\
\

## Conclusiones finales

\
Para condensar los hallazagos claves, es esencial repasar que aunque las reseñas tienden a ser positivas, la correlación débil entre polaridad y puntuación indica que el sentimiento expresado en texto no predice bien la valoración numérica. Añadido a esto, la relación entre polaridad y puntuación depende del género, por ejemplo: en romance y aventuras hay correlaciones positivas, mientras que en drama o thriller tienden a ser negativas, lo que refleja diferencias en cómo se verbalizan las valoraciones.\
\
Los resultados demuestran de manera contundente la superioridad de los modelos supervisados sobre el enfoque léxico para la clasificación de polaridad en reseñas cinematográficas en español. La regresión logística emerge como el método preferente para aplicaciones generales, mientras que el Naïve Bayes ofrece una alternativa interesante para casos específicos donde se priorice el rendimiento en clases particulares sobre la precisión global.\
\
A pesar de esto, cabe puntualizar que el mal rendimiento del método léxico en este contexto específico no implica que sea inviable en otros dominios. Su valor fundamental reside en su eficiencia computacional y rapidez de implementación, ya que no requiere entrenamiento previo y puede aplicarse inmediatamente a nuevos datos, por lo que su rendimiento puede mejorar sustancialmente en otros entornos. De esta forma, probar con nuevos datos este enfoque sigue siendo algo aconsejable. 
\